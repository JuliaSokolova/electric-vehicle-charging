{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from typing import Callable, List, Dict\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark as ps\n",
    "import json\n",
    "import requests\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Always make it pretty.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "spark = (ps.sql.SparkSession\n",
    "         .builder\n",
    "         .master('local[4]')\n",
    "         .appName('julia_json')\n",
    "         .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- clusterID: string (nullable = true)\n",
      " |-- connectionTime: string (nullable = true)\n",
      " |-- disconnectTime: string (nullable = true)\n",
      " |-- doneChargingTime: string (nullable = true)\n",
      " |-- kWhDelivered: double (nullable = true)\n",
      " |-- sessionID: string (nullable = true)\n",
      " |-- siteID: string (nullable = true)\n",
      " |-- spaceID: string (nullable = true)\n",
      " |-- stationID: string (nullable = true)\n",
      " |-- timezone: string (nullable = true)\n",
      " |-- userID: string (nullable = true)\n",
      " |-- userInputs: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- WhPerMile: long (nullable = true)\n",
      " |    |    |-- kWhRequested: double (nullable = true)\n",
      " |    |    |-- milesRequested: long (nullable = true)\n",
      " |    |    |-- minutesAvailable: long (nullable = true)\n",
      " |    |    |-- modifiedAt: string (nullable = true)\n",
      " |    |    |-- paymentRequired: boolean (nullable = true)\n",
      " |    |    |-- requestedDeparture: string (nullable = true)\n",
      " |    |    |-- userID: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loading data from .json into pyspark DataFrame\n",
    "spark_df_all = spark.read.json(sc.wholeTextFiles('./data/acndata_sessions_3years.json').values())\n",
    "spark_df_all.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+------------+--------------------+------+-------+-----------+-------------------+------+\n",
      "|                 _id|clusterID|      connectionTime|      disconnectTime|    doneChargingTime|kWhDelivered|           sessionID|siteID|spaceID|  stationID|           timezone|userID|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+------------+--------------------+------+-------+-----------+-------------------+------+\n",
      "|5bc90cb9f9af8b0d7...|     0039|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|       7.932|2_39_78_362_2018-...|  0002| CA-496|2-39-78-362|America/Los_Angeles|  null|\n",
      "|5bc90cb9f9af8b0d7...|     0039|Wed, 25 Apr 2018 ...|Thu, 26 Apr 2018 ...|Wed, 25 Apr 2018 ...|      10.013|2_39_95_27_2018-0...|  0002| CA-319| 2-39-95-27|America/Los_Angeles|  null|\n",
      "|5bc90cb9f9af8b0d7...|     0039|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|       5.257|2_39_79_380_2018-...|  0002| CA-489|2-39-79-380|America/Los_Angeles|  null|\n",
      "|5bc90cb9f9af8b0d7...|     0039|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|       5.177|2_39_79_379_2018-...|  0002| CA-327|2-39-79-379|America/Los_Angeles|  null|\n",
      "|5bc90cb9f9af8b0d7...|     0039|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|Wed, 25 Apr 2018 ...|      10.119|2_39_79_381_2018-...|  0002| CA-490|2-39-79-381|America/Los_Angeles|  null|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+------------+--------------------+------+-------+-----------+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creatine table for charging sessions\n",
    "charging = spark_df_all.drop('userInputs')\n",
    "charging.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------------+----------------+--------------------+---------------+--------------------+------+\n",
      "|WhPerMile|kWhRequested|milesRequested|minutesAvailable|          modifiedAt|paymentRequired|  requestedDeparture|userID|\n",
      "+---------+------------+--------------+----------------+--------------------+---------------+--------------------+------+\n",
      "|      350|        59.5|           170|             550|Mon, 30 Apr 2018 ...|           true|Tue, 01 May 2018 ...|    22|\n",
      "|      400|         8.0|            20|              60|Mon, 07 May 2018 ...|           true|Mon, 07 May 2018 ...|    61|\n",
      "|      400|         8.0|            20|             648|Mon, 07 May 2018 ...|           true|Tue, 08 May 2018 ...|    61|\n",
      "|      400|        28.0|            70|             648|Mon, 07 May 2018 ...|           true|Tue, 08 May 2018 ...|    61|\n",
      "|      350|        17.5|            50|             546|Fri, 11 May 2018 ...|           true|Sat, 12 May 2018 ...|    22|\n",
      "+---------+------------+--------------+----------------+--------------------+---------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating user input table\n",
    "user_input_0 = spark_df_all[['userInputs']]\n",
    "\n",
    "#removign None values\n",
    "user_input = user_input_0.na.drop()\n",
    "\n",
    "#unpacking list with RDD faltmap method\n",
    "rdd = user_input.rdd.map(list)\n",
    "rdd1 = rdd.flatMap(lambda x: x[0])\n",
    "\n",
    "#movign data back into data frame\n",
    "users = spark.createDataFrame(rdd1)\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#savign tables to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "charging = charging.toPandas()\n",
    "charging.to_csv('charging.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.toPandas()\n",
    "users.to_csv('users.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
